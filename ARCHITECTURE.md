# AI Configuration Architecture

## System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Your Application                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                   API Routes                          â”‚   â”‚
â”‚  â”‚         (app/api/generate/route.ts, etc.)            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                   â”‚
â”‚                           â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              AI Client (lib/ai/index.ts)             â”‚   â”‚
â”‚  â”‚                                                       â”‚   â”‚
â”‚  â”‚  createAIClientFromEnv()                             â”‚   â”‚
â”‚  â”‚    â”œâ”€ Reads environment variables                    â”‚   â”‚
â”‚  â”‚    â”œâ”€ OPENAI_API_KEY                                 â”‚   â”‚
â”‚  â”‚    â”œâ”€ OPENAI_BASE_URL (optional)                     â”‚   â”‚
â”‚  â”‚    â””â”€ OPENAI_MODEL (optional)                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                   â”‚
â”‚                           â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         Provider Registry (lib/ai/index.ts)          â”‚   â”‚
â”‚  â”‚                                                       â”‚   â”‚
â”‚  â”‚  Providers:                                          â”‚   â”‚
â”‚  â”‚    â”œâ”€ gemini                                         â”‚   â”‚
â”‚  â”‚    â”œâ”€ openai â—„â”€â”€ Custom Path Support                â”‚   â”‚
â”‚  â”‚    â”œâ”€ claude                                         â”‚   â”‚
â”‚  â”‚    â”œâ”€ groq                                           â”‚   â”‚
â”‚  â”‚    â””â”€ cloudflare                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                   â”‚
â”‚                           â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      OpenAI Provider (lib/ai/providers/openai.ts)    â”‚   â”‚
â”‚  â”‚                                                       â”‚   â”‚
â”‚  â”‚  new OpenAI({                                        â”‚   â”‚
â”‚  â”‚    apiKey: config.apiKey,                            â”‚   â”‚
â”‚  â”‚    baseURL: config.baseUrl // â—„â”€â”€ Custom Path       â”‚   â”‚
â”‚  â”‚  })                                                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚         External API Endpoint           â”‚
        â”‚                                          â”‚
        â”‚  â€¢ Standard OpenAI API                  â”‚
        â”‚    api.openai.com/v1                    â”‚
        â”‚                                          â”‚
        â”‚  â€¢ Azure OpenAI                         â”‚
        â”‚    your-resource.openai.azure.com       â”‚
        â”‚                                          â”‚
        â”‚  â€¢ LocalAI                              â”‚
        â”‚    localhost:8080/v1                    â”‚
        â”‚                                          â”‚
        â”‚  â€¢ LiteLLM Proxy                        â”‚
        â”‚    localhost:4000                        â”‚
        â”‚                                          â”‚
        â”‚  â€¢ Any OpenAI-compatible API            â”‚
        â”‚    your-custom-endpoint.com/v1          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Configuration Flow

### 1. Environment Variables (.env)
```
OPENAI_API_KEY=sk-your-key
OPENAI_BASE_URL=https://custom-endpoint.com/v1  â—„â”€â”€ Custom Path
OPENAI_MODEL=gpt-4-turbo
```

### 2. Client Creation
```typescript
createAIClientFromEnv()
  â†“
Reads .env variables
  â†“
Creates AIClient with config
```

### 3. Request Processing
```typescript
client.prompt("Hello")
  â†“
Selects provider (openai)
  â†“
Gets provider config
  â†“
openaiProvider.chat()
  â†“
new OpenAI({ baseURL: customUrl })
  â†“
Makes HTTP request to custom endpoint
```

## Key Features

### ğŸ”§ Flexible Configuration
- Environment variables
- Programmatic configuration
- Runtime provider switching

### ğŸ”Œ Multiple Endpoint Support
- Standard OpenAI
- Azure OpenAI
- Self-hosted solutions (LocalAI)
- Proxy services (LiteLLM)
- Custom implementations

### ğŸ”’ Secure by Default
- API keys in environment variables
- No hardcoded credentials
- Supports different keys per environment

### ğŸ¯ Easy Integration
```typescript
// Simple
const client = createAIClientFromEnv()
const response = await client.prompt("Hello")

// Advanced
const client = new AIClient({
  provider: 'openai',
  openai: {
    apiKey: 'key',
    baseUrl: 'custom-url',
    model: 'custom-model'
  }
})
```

## Provider Interface

All providers implement the same interface:

```typescript
interface AIProviderInterface {
  name: AIProvider
  chat(messages: AIMessage[], config: AIProviderConfig): Promise<AIResponse>
  isConfigured(config: AIProviderConfig): boolean
}
```

This ensures consistent behavior across all providers, including custom endpoints.

## Configuration Options

### AIProviderConfig
```typescript
{
  apiKey: string        // Required: Your API key
  model?: string        // Optional: Model name
  baseUrl?: string      // Optional: Custom endpoint â—„â”€â”€ NEW
  accountId?: string    // Optional: For Cloudflare
}
```

## Usage Examples

### Standard OpenAI
```typescript
openai: {
  apiKey: 'sk-...',
  // baseUrl not needed, uses default
}
```

### Custom Endpoint
```typescript
openai: {
  apiKey: 'your-key',
  baseUrl: 'https://custom.com/v1',  // â—„â”€â”€ Custom
  model: 'custom-model'
}
```

### Azure OpenAI
```typescript
openai: {
  apiKey: 'azure-key',
  baseUrl: 'https://resource.openai.azure.com/openai/deployments/name',
  model: 'gpt-4'
}
```

## Benefits

âœ… **Flexibility**: Use any OpenAI-compatible API
âœ… **Security**: Keep credentials in environment variables
âœ… **Development**: Test locally with LocalAI
âœ… **Cost Control**: Use different endpoints per environment
âœ… **Compliance**: Host in specific regions (Azure)
âœ… **Performance**: Use faster proxies or edge deployments

## Testing

Test your configuration:

```bash
# Check status
GET /api/ai-test

# Send message
POST /api/ai-test
{
  "message": "Hello!"
}
```

Response includes:
- AI response content
- Provider used
- Model used
- Token usage
- Available providers
